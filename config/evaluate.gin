import visualizer.transforms.transforms
import visualizer.evaluate.evaluate_model
import visualizer.architectures.unet_pruned
import visualizer.datasets.brats_dataset
import visualizer.utils.preprocessing
import visualizer.data_loader.data_loader

INPUT_HEIGHT = 240
INPUT_WIDTH = 240
NUM_CLASSES = 4

# Data transformation configuration
# TRANSFORM_CONFIGURATION = {
# '0': {'transform_type': 'Resize', 'params': {'output_size': [%INPUT_HEIGHT, %INPUT_WIDTH]}},
# '1': {'transform_type': 'NormalizeImage', 'params': {'mean' :128.0, 'stddev': 128.0}}
# }
TRANSFORM_CONFIGURATION = {}
configure_transforms.config = %TRANSFORM_CONFIGURATION

BraTSDataset.root_dir = '/scratch/dpadma2s/neuroscience_lab_data/extracted_images/test/'
BraTSDataset.transform = @configure_transforms()
BraTSDataset.input_height = %INPUT_HEIGHT
BraTSDataset.input_width = %INPUT_WIDTH
BRATS_DATASET = @BraTSDataset()

# Data loader configuration
get_train_valid_test_loader.batch_size = 1
get_train_valid_test_loader.random_seed = 39248
get_train_valid_test_loader.valid_size = 0
get_train_valid_test_loader.test_size = 1
get_train_valid_test_loader.num_workers = 0
get_train_valid_test_loader.dataset = %BRATS_DATASET
DATA_LOADERS = @get_train_valid_test_loader()

# Architecture- UNet Pruned
Unet_pruned.num_classes = %NUM_CLASSES

# Evaluation
evaluate_model.net = @Unet_pruned()
evaluate_model.num_classes = %NUM_CLASSES
evaluate_model.visualize = True
evaluate_model.data_loaders = %DATA_LOADERS

# get_bg_weights.num_characters = %NUM_CLASSES
# get_bg_weights.bg_class_weight = 0.08
# torch.nn.CrossEntropyLoss.weight = @get_weights()
# evaluate_model.criterion = @torch.nn.CrossEntropyLoss()

# focal_loss.alpha = 1
# evaluate_model.criterion = @focal_loss

calculate_weight.data_loaders = %DATA_LOADERS
calculate_weight.num_classes = %NUM_CLASSES
calculate_weight.loader_idx = 2
calculate_weight.report_path = "report/"
torch.nn.CrossEntropyLoss.weight = @calculate_weight()
evaluate_model.criterion = @torch.nn.CrossEntropyLoss()